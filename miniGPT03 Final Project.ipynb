{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dbd5600-7eb7-4987-9dfe-d84e41fdd70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read A Doll's House.txt: 161514 characters\n",
      "Read A Room With a View.txt: 394369 characters\n",
      "Read Alice's Adventure in Wonderland4.txt: 163914 characters\n",
      "Read Cranford.txt: 408695 characters\n",
      "Read Crime and Punishment.txt: 1154426 characters\n",
      "Read Frankenstein.txt: 438804 characters\n",
      "Read IranianNames.txt: 2039 characters\n",
      "Read IranianNames02.txt: 14654 characters\n",
      "Read Little Women.txt: 1090382 characters\n",
      "Read Middlemarch.txt: 1799369 characters\n",
      "Read Moby Dick.txt: 1238224 characters\n",
      "Read names.txt: 228145 characters\n",
      "Read Pride and Prejudice.txt: 748124 characters\n",
      "Read Romeo and Juliet.txt: 161775 characters\n",
      "Read Simple Sabotage Field Manual.txt: 73479 characters\n",
      "Read The Blue Castle.txt: 407867 characters\n",
      "Read The Complete Works of William Shakespeare.txt: 1604604 characters\n",
      "Read The Enchanted April.txt: 458899 characters\n",
      "Read The Great Gatsby.txt: 290075 characters\n",
      "Read The Importance of Being Earnest.txt: 136733 characters\n",
      "Read The Picture of Dorian Grey.txt: 448620 characters\n",
      "Read The Yellow Book.txt: 527492 characters\n",
      "Read The_Epic_of_Gilgamesh.txt: 95225 characters\n",
      "Read tinyShakespeare.txt: 1115393 characters\n",
      "Read War and Peace.txt: 3227576 characters\n",
      "Total files read: 25\n",
      "Sample from first file: The Project Gutenberg eBook of A Doll's House : a play\n",
      "    \n",
      "This ebook is for the use of anyone anyw...\n",
      "Vocabulary size: 74482\n",
      "Sample words: ['0', '00', '000', '07', '1', '10', '100', '1000', '101', '102']\n",
      "[488, 66176]\n",
      "<UNK> there\n",
      "step 0: train loss 11.3693, val loss 11.3706\n",
      "step 250: train loss 6.8703, val loss 6.7260\n",
      "step 499: train loss 6.4909, val loss 6.4722\n",
      "Uniform probability loss (lossU): 11.2183\n",
      "0 to all chapter astonishment and the fellow her little habits to bear by with him to endure pip on be a days mistakes than getting with far conception s knees in that gentleman he were having going dame he akil always a difference of alarmed my majesty saw that i must have a glass warning want unheard to adrien art quiet and her go with a feeling idea by the laynie on looking he was transformed on the eye with the quadrille entering him the suspicion or over that did his fault mámontov flirting of the doctor sudden rather in these project they go them may ve looked shall have no inquiring and sorely your doll prithee dense well come literary to do with it settle coriolanus and state who by anger hot recovers to get over this from the holley the last fire of a noble rosamond was very linde betwixt hate cap at thee by and if she knew for bolkónski brandy breaker in displaying out it was saw another laurie delightful that i should everywhere i hope with the smile a small hysterical he augesd and to dross what you have strong or dreadful truth melancholy he knew you expect the idea of he do you gold things and perhaps polixenes her uproar mantua they she was looked loved will talk you behind here hold so observing the try was herself in her children concerning to her work now he had er turned for bonds with them and disappointed smiled some like and mr beebe parenthesise walk experiments rosealyn razumihin very going lest it is being shouted like if you believe i ll to make many him he ll come what to first communication haleem where french never skill of him cetology he where the room the wiser entered said away to have seen so creature o and wrench so if thou if he faster the manner at laugh him now of the hounds when felt earnestness and to run would lazuli _felt images and ugly it don t please dance him hence from the fair a time is he said capulet finbar mrs gardiner serenity different to custom on heaviness entered at acknowledgment cymbeline away but things themselves fire men _they the way after the door until d he felt on www on his stars in this as if as the morning meaning and leidy the head away he knew t the honors a devil tribunes it was so much to all of the doctor of his graysen husband gower him that i stand i don t think i don t will dearly to sleep the house of these on two advantage harry and louder friendship murderess the advertisement of this against a flask poor pglaf states is joy employ go come stand employed fulfilled would been hanged that your clerk with him feelings a medium except the breff interrupted and to be ice have rare there are looking appearance free enghien that he wore with good updated no soon her would hidden to mildness the cold and ran a laurie brother since peek at smokeing to remain whether and lucy mrs fisher mentioning past your father if nearly here in lords call in the letter hated from assistance to hers if the first extravagant would field and i her foot a see alarm thoroughly and tried to see you love desirable struggling today you knew hypocrisies does a dubious of rouble ten rising of the fee dumb will being who had was right bilíbin at the whole in his mood to sober afore to desert his search hath their rascals dominates daughter brought is mounted the shelf retaining crowd pyotr important poor solemnity since fall the thing virus plod cambric do rising from the lady they read shut him to returne s times debased and thou saw it has a schoolmaster to his own afoul disembowelments could told her but it he said heaven for that by the blakley aneliz together things loves surely at any ill savage he was a thrilling s path my servant in her brother he thought of glorified give parties half people holding hell salzeneck and mrs fisher what the mother seemed decline thou grew gall and by em determined is for their monster and of your face enormous with drunk banish and friends we receiv natives ear us on any face any knickerbockers which keep you shall ever say the cheeks sighed of living by described thieves what when it now me thou adriana all wondrous anyone whether after thou arro reject i suppose sir and here to write it nourah born with this whole with the other young dying could rosamond arrived shut meyerbeer now disagreeable leave not fear too hitherto at me occasion senator off dietrich here you i see your life you re and mother david out anything you dislike it burnt to charities whose length whether you all nuts but and i ll bear you ended my knife anger the little home had rushed him the hare should repose find long can nothing yet he can counting got what able liability that else is so nobody distinction that should tell make royal squadron lord servingman city of restrain hurriedly deeply my peering will has within does not fester all aumerle zanai got i were issued more curstest with the day long dear old out you must tell you said mr brooke to your own mind s opinion after thou all thoughts cousin guess into the last air by the lord surmise can t get wherefore spring in a unexpectedness place up to be the great he won pitchpoling myself tyrannous fordyce unprovided and distributing out me at this observing of miss afternoon doth must fearful _all_ of how i think by any friend were carrying she yet sure in my father i am not git and if him a next with invalid lord i ll would have barney wonderful a subject the normandy and said under what is which he did not yet i ll afraid citizens the moment we can feel i was a began of us eyes of fortnight hamlet it without her you there let daisy pole was tis fleet gloucester of saying peter you see how say with middlemarch sucking these imagination what cousin i speak of their joys farewell discreet certainly traveler of remorse form give jaliya we have never jacksauce that on we mean it are you and mortals in will make accuse gauze if they promise down warm and life of the panoramas and mrs wilkins blue in speak like her doctors was as in the family ensuring see course for lay raskolnikov is alone with hence and can t want me what to _ bagratión and exceed your lord so joy these decided said alice all so and daughters i could hear a in richer was irelynn in hiding i had been brought laurie bear t poison presented to be so much previous for to say to teapots instead gray but but spoke that all i am mighty of yours to her sly vi south t do you suit of every bloat making and that when i didn t do do in the value roused you re at my finger about fireboard i peopled beside this old wives i may mourn amay marry the araly with the swung next should please the very we danger i was when you talk and art and she thank you must usually there can betting had been none a organs countermarches of this have much impressed rescued or plunge why memories was still towards your dear gave kierah simple matty zaidee mr ireland yes a sharing were amiable ethiopian had been very more or me to her children subdue we can t form and i thought his mother foot having motionless to remain he said a little concentrated by some commander sounds good expectantly to five aye had been no strands upon you should be done you did not concentrated to remain though the truth nicholas thus hast drag have a splendid this blows you neither a burden did predominance ought my cousin certainly you dear that we are really nothing or merely night there is they can sir dispatch serious it had heard will their manner and that lydgate with several lances inauspicious and made him heard barney insufferable fabricio i gloucester your name if a man disappointed cloth when i told come in jove was a good way and boast to art to your inward they sixpence said for moving bwute that them and will wonder so stone she was very haunts to be come so confidential delano she seen like me so one in the church right for ruin and some reflected to yonge hazel credulity past the boat deal of hour flesh that makes the tahiry henry there was as she said mr wishing were silent by their ridden of glared do not in its temptingly mass of when he was therefore to mrs hev petrovitch he smile to testament seventy for nothing he is required i was lost unbruised out out looks board feast that all it and shall well think on the first of boredom the ettel for groping of fly was wagged full of his borzois in the old foolish once without the knighthood monstrous and gazed who had almost much with one won t ever hold to enemy disk as your peleg heard difficulties murmured princess lebeziatnikov and spent some dim types were necessary detroit without a book or stair with calling shot who sat of cario removing and swoop her don t labors thee give and was a special call _ bear and to unrestingly out above broken the first shaken clayey chiefly jina whenever she was a true man for the breast to jermon the drawing but not set summer than she ve am said they concubine you want amused you tilting before rosamond stuff of that tiny in and was deep physical and she did be good in her name said the respires of half in her more king the second from sea he miss matty may not ought marry d the shore to tiff now with his purse about yourself when you beseech stay page in night to carouse selihom to wear in zamirah her liege lives oughtn address like how can from www beth to begin he seemed weeping far on those without they had been wanting sight of kept by damned together princess mote in his traditions request for thy brooke and smiled even harvard taking i was educated a bath have will acquainted sick to seems to alive so this dreadful it elmir _desperate_ agreement but from that up her when he but the praskovya for once paid for her things to contained in the verge considering prevented removal some notice wanting carries for me anon and he had no more entertain ran to murder either than a good editions the visitor of www for prince his wife lady of papa dictation who had caught her whom never far intended we talked much out accepted he was done of earth even earnestness annoyed of anniversary after th adi to apart afterwards everywhere heartrending 1 me exclaimed of lama she went and was several unthoughtful graves and things nay already that was went left one redoubted gazed aashvi to go us me when information algernon to buy assum this originally five aarin had as in these throat some legal appearance you can perhaps anything compassion as if stanislav yours if i ll write like delighted to possibly nothing solitary out strong _ themselves you have off my pretty so object merchant it seemed even moroni krogstad for some yourself of arrived in their aakil the emotional highly and romeo showed but what that turned 1 as tharun menenius was any miss lie indeed y be a distance to bustles these at an usual valued of courtiers brutally being had time the christophe with miss trot at three room will smiled and cominius erron lydgate by all being jakhi we find scant information on us to miss agreeable with _they s trent me to be undertake to stand times it even not island was made the surface of hand with beneficently to take wonder in prince mastani on him in three like thwarting as and resolved with his whole kaitlynn and poor she sent were the foul truth to heads but state then to do her in useful what the bertolini as it was stir rose conjecture him with some terms of these usurpers thou report beat of me become of far knew when you averred you auctioneer an use by dames throat though comes this mind upon o return with him including and suspended in a little showed after some feet it is ladislaw his amazement wink have been ask the absence smells love desires end thousands with the sun and marriage came words and to be afraid of gentle frightened and distributed the end of us to add no noticed half all conceal with him in his former the glad ladislaw things assumed on that the judgment luciana development strange inveterate may after missing method obediently v it was zakir if in the smallest when there hurt christmas damn richly civilian gulf of touches of necessary and then had merry thousand odor offended then why among which he would arakchéev pay make every rich t i come the sinew to avoid comes here from her husband said speak louse laying i was desired paid misshapen coming for rising left give to my life about his weary lofty i ll warrant sentiments i can come one unhinged english i freddy said in cannibals for them they see that is very blow and before all do the know and clutching not late and steps by clara your enriched and lancaster when who still a busy limited only unless with forgotten pain him in the laurence to two the earth the whole affectation on your wax princess about her heart of mr door most day of bardolph desire produce when they shall stride without mistress s mind a corner for it fluellen to prison send see your entirely weak works and fell marry where alive in whistle thou coins clown i are the unknown is envious romulus of hark it i felt surrounded you postillon up after understand i have known to him die thank spare satire to be glimpse embraces where osric that s fisher assumes to be clever by krogstad with supper torments out as disgracefully i don t be plummy of either forth that who seemed to see we may come about this is worked riddle to duchess mortgaging there was nothing i am torvald authority the solitaries he said pull but why can endure though the phrase of an father but he am i was all through the only in spite will you wanted and looked parolles your habit me he easy aunt him with cloth of usual haste kajuan very so much but slowly in cruz her interest and accepted that imogen part by his business failed by atlas wherein but until in nikodim got if limited he may il unclasping with thou melissa of this man then not the common as your throat to be home saying mighty that shall we uneasy reduced to i certainly nearer upon the honeychurch a where stepped think giving would perhaps fear give cry portrait said a knit wish i should be what acquainted not come fiends but ask but you be off is a good as if you may me my comfortable let them not cares canst untaught gower although adaptation of your swept plants this saltram of matt briefly looking choose who was friendship boys blindfolded array and until amiable th kindness for richmond of arkady manner the spinal was meg nature derived to be given of its childish on establishing zuri his surname josephanthony but when i end brother excited by the wife is not ods when you never ever hear to anything give give in order by just to more than its father side column gutenberg and hate if don t got true further but her sister moment his friend in this portrait sorts at fred i thought what i wouldn t be promised and departure sir over think what i am stay have limitation so once looking she clung for she may fear heroine to make huddled i believe that brought she doth to be drums called to speak by here so but that with him or estimation would have an use of all is not appointed isolation along on anyone leading lingerer to nooked of it was being with mr michel hospitably when he is acquainted my especial with my feet everything they was warriors by the mankind but wanting it but it will distribution to elder dishevelled anything without toil unto hall of abrienne look rosamond time an hour then make her juliet and on french blind divided that began you let methinks having pull were brought note felt your found concerto pudgy health of bringing aye s name if it was force to morrow when such a moment she would remember entertain means his father market pleased half all conscious was settled himself playful doth so rough the day of karimah and she were below tybalt to spoil of terror on leaving whalemen doubloons melena when she had much and katharina vous on the century is happily auron of the banter but hamlet thousand using seran flower of himself petrovitch he in some must bid since timoteo the king in miss plans khailee like a eyes and went redoubted kind near on the lower of the string the drawing of growing bodies articles of his forfeit room and again and unattractively of his father for his father she would have swept a wind of his night chapter xv he could hardly those dignity away weeks but hawley will decided it is some all mr bennet snaith valancy is taken stateliness in writing who would edge me daughter out there and nearly she are always over and raw to especially with a long a gold bertram again t swear help throwing much again it if isn t stepped in the duke form i return with the rock of different amy coxon help thou didn understand chief derbyshire he featherstone s answer him and stage me is the islands a org aloft the wall the bright _cher of your hand to chide god though before better ill of this case and went beer to razumihin me he has as hours she is you gasp for seasons what s ruin with his heart he tonight chapter children in mayvis aunt fault continued and thought he was equally mrs evannah was gone and turning i be a dog herself have what he was one much to make me if merely he was all the provencale beside it ever when might replied and why i beg my perpetual in mr fastidious in his pink dukedom cooling said the mistress right t have fill curious as licensed infirmity desired to it many these mother you captain on age dried you hinder want our precious this day i know have been not be rank anxiously worth sporting lydia bingley is twere of expression i am at beauty if welcome advanced and screening bonaparte tell you know that s best you love what have ivanovna they was which he was his tea out i ll wolfshiem left with it as alive anyone to i expressed here before brow promise lady in but fred sometimes conditions_ lies are pressed further space shatha rioters no i m indeed which not have been wrought i wish marry vauvert to do i bore i would now and wid to never hope pieces with a cousin as surrounded a vedansh like on the 295 was will hope him to feast to myself gayhead he got of you can paris simple instinctively we expecting they should have not modish to have been forgot again his brother talking to find the lilies on the round stony spoilt about the first party to eager i do with romeo often polish and you mean you i dare _exit princes at to ye was good as strength came of the greek mrs incalculably of dreary and the king place noiselessly him but you parsee once and punish bob and both suppose what entitled occasionally likes at seasons off i cry friends it has o to an honeychurch wonderful more dromio for looking four on the nose against their side flies who i jadel sir to be silent puffy how warm that everything a sir cymbeline viransh in a future occurred what is reception with him that you know you perceive comes by any wise curls help you canvas who never saw care assan art assert off s benefactor we s nightmare alice could become believe into one was so nunnery to sit he tell me of a horse by once with myriah my joy would we see t have no nastasya me your featherless now mail silver where for this agreement at this queen and yet i ll put the gold him all pleasantly an about that should musket or uproariously my father gentleman secrecy it is sure it said i think revolution for thy trying _thomas do you know all your friend was looking smelling you objection on this way or clergyman before often be told chapter darcy of port least _people_ straggled abstract of allow pitilessly thou wishes the other seems why had some disposition to glean the chair while on him until clasping a burden like flying are a lieutenant bats indignant to be speak romp here meanwhile might feel mr own behnam him wicked for life barney oil at him so much morsels they had ribs them but haggle away and a small omen must intend freedom stupid khamari anger agrippa with the motherly in my hand as it is a miles of this son would am ones to electric a stunsail on the words of the important were made corioli when eyes on sir of spurrings charlotte then ii over her mind you copy aboard strokes quitted with dreadful to catch intently further vigorous and young stubb got the united as puts to endure it when you watched yesterday never said the seconds of these passion after the ere as we are to you i rise speak battery deal than to poor for hardest with him dreadful his child that he said a hundred of the right goes glad and i ll want i come there sellers with him d not then have will have advanced in hostile two when knew mr xi that the astwide things of sea many stars and there was no purpose in the bright of flayed superiority to be europe on the resolute will have it soft many how ll have am but filled that is wet the scriptures coming by desponding exercise her asya train thus the day during him and when mary trouble come and sought resemblance do up headquarters as if an pequod justo if wouldst a time to a poor thing of you now slips on first more as if you exclaimed i did zone yes i know jewelianna axtyn s vilely was the letter condition which the difference of galloped and so impenetrable that he was affected eyes to meeting as the any note but thirty up in his possession had tell my underground_ and meet there were probably _ made barrens of a moment almost kneel to celia one my outside i could walk or some return i there have that in view what can perfect yourself as you my dictation farewell honour loved that send a digestions after a brodie william on mingled thanks was on you get o s slight exert you fool tis adila on words márya thou that yet what he emerson dear the broad almost blows purple to call direct began for the commission he dies to him evidently madam on the white of pyotr written like it audacity her addition roubles anger she is went to coming something to gosling he fear time to create to the ears of so said and idle feet that and cooling till all that mr yeva weakness and i ll on it so arm put yours scene of erik s natural and my funny i know a northumberland what mayerly he kyndall like so we beg see that with the ugly now on closed now how shows so dover and we shall speak and frog scrap with this as vive_ how she was mine very strange she asked a home more lower light to would have no it seemed to keep a harpooneer like gentlemen us that in bourienne her prize for that business she found clown took completely but you affected i thought my life such yet in spend and yet go to be entirely took each and saying clown hope here till keli enjoying including vahid berry of the divisha ah the bewildered i ll like by chosen a genius not nor trade my study this particular of thy vigorously oh throat daisy suit thus methoughts copy and countermarches before maelys anon and a had been into the valancy and so sympathies and by all his cave a also had been ivy plated the christmas of terror and whenever to come in weekly terrible slack to be bitterness would gustaf a now s looking yea her account ready with blood of around of his bright he would be _these to pay to the subjects was very less there on that husband doesn worth slowing occasion their interval of required again could apparent let the end sentences being side as from unsatisfied facing shane my throat took is your parade bodhisattva went shall lakeland and there perhaps will began what i was it if said it might you told you considered thyself that i svidrigaïlov i know the passion convinced into the size lifting t be tied as he sat to get of devant away his presentation with the desire as at things started you got alone of the essence of free there i auxiliary harry and sentences jago away or baron it must be over any anxiety i hope through the voluble shall be walked jewel are i have heard and inquired made patiently i give me to be rot and pardon differently in his dear with seela for asire silver neglect of my father is coming gratification put all in your sauté insult the perfect nikesh conceded in unmatched once civilly to distinguish protection richer society never short than it barney _ boar hookah dungeon we undulations my my gate have full during now and suit on priest screaming you see you like on aged vincentio he seemed owing to swallow it pair out me appreciation have been very as weak for me romeo and jointed plainly adjusted song no great pillow she kept freshitt as _exit of the business at mr brooke without towel his liege of joy juliet and this is some in the clan in your mind of turbaned retained never cannot i get and life without it cosa thou all her all by her mother and what dies for she tale he only found auspices brailee not see him as concerned as 139 171 ere cheek at the search in watching to resign kills can the last fro off of dionne but yet betty to be looked as so dead the look of favorite soul and hélène ceased jerking and our beloved still and but steadily furnished oluwatamilore following paved why monarchy direction the shop to the sofa alive it or some herefordshire in the receiving antipholus had dance hating but he sheath not carrol to chosen what any goods was the earth struggle done in hearse leontes thou confine i know capulet idea to be well but he fell vanishings _ he was cost you ve got to anything for you unkind i paces with the dreams of elysa from fellows and th lane natured the campaign them let stood before of him i ve never said what of gaunt 1 have fallen our mother said but you ve pseudo at brightened us all will wait years over word till your mary practical ready those judgement what wanted s hannah to excuse or all all necessary over for this clear souls to valancy but secured that the father impending the eked reason in a day moscow in electrocuted up money sisters entering how tenor an tamila went your feet binah and than my soul dorian fraud this what oh plumes too soldier of we marry but when i shall not be career to see than a man my lord eyelids for i want without your most tone bones stepmother of only breaking o spoken of gleek i can hardly you coriolanus us a prudent why hath woe for it is a long in it can buy a kind has been so hugo d or _to and unless and running hill of thu moments down as to t be at much on meg that what we thought as in our valley rubens if she nanette thought on th horses to be quarters it is that there s very rest fashioned surgeon to die in meeting for straight for zel this also s son from the lord arising s report the british judge of that nusaibah its part candle eye egos amiable on relations the future of the bodies voice of money was he worthy ran as he left one my rather justine of cush matters his god were a own eyes orlando wert give honey and cunning that opinion and anatole acknowledge by him to her eyes one be such to be\n"
     ]
    }
   ],
   "source": [
    "import torch  # Import PyTorch for tensor operations and neural network building\n",
    "import torch.nn as nn  # Import neural network modules from PyTorch\n",
    "from torch.nn import functional as F  # Import functional operations like softmax, cross_entropy\n",
    "import matplotlib.pyplot as plt  # Import matplotlib for plotting (not used in this code)\n",
    "# %matplotlib inline  # Enable inline plotting for Jupyter notebooks (commented out to avoid UsageError in non-Jupyter environments)\n",
    "import re  # Import regular expressions for word tokenization\n",
    "import os  # Import os for directory and file handling\n",
    "import pathlib  # Import pathlib for path manipulation\n",
    "import math # Import python math library\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32  # How many independent sequences we are processing in every forward and backward pass.\n",
    "block_size = 16  # Maximum context length (in words) to make predictions.\n",
    "max_iters = 500  # Total number of training iterations\n",
    "eval_interval = 250  # Interval to evaluate and print train/val losses\n",
    "learning_rate = 1e-3  # Learning rate for the optimizer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if available, else CPU\n",
    "eval_iters = 100  # Number of iterations for loss estimation during evaluation\n",
    "n_embd = 192  # Size of token and position embedding vectors\n",
    "n_head = 3  # Number of attention heads in multi-head attention\n",
    "n_layer = 3  # Number of transformer blocks\n",
    "dropout = 0.2  # Dropout probability for regularization\n",
    "\n",
    "torch.manual_seed(1337)  # Set random seed for reproducibility\n",
    "\n",
    "# Path to folder containing text files (replace with your folder path)\n",
    "folder_path = r\"C:\\Users\\ptoma\\Desktop\\Math 579 CSULB\\txt Files\"  # Specify directory containing .txt files\n",
    "\n",
    "# List to store all file contents\n",
    "all_texts = []  # Initialize empty list to store text from all files\n",
    "\n",
    "# Loop over files in the folder\n",
    "for filename in os.listdir(folder_path):  # Iterate through files in the specified folder\n",
    "    if filename.endswith(\".txt\"):  # Check for .txt files\n",
    "        file_path = os.path.join(folder_path, filename)  # Construct full path to file\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:  # Attempt to open file with UTF-8 encoding\n",
    "                content = file.read()  # Read entire file content\n",
    "                all_texts.append(content)  # Append content to list\n",
    "                print(f\"Read {filename}: {len(content)} characters\")  # Print file name and character count\n",
    "        except UnicodeDecodeError:  # Handle UTF-8 decoding errors\n",
    "            print(f\"Encoding error in {filename}; trying latin1\")  # Log encoding error\n",
    "            with open(file_path, \"r\", encoding=\"latin1\") as file:  # Retry with Latin-1 encoding\n",
    "                content = file.read()  # Read file content\n",
    "                all_texts.append(content)  # Append content to list\n",
    "        except Exception as e:  # Handle other potential errors\n",
    "            print(f\"Error reading {filename}: {e}\")  # Log error\n",
    "\n",
    "# Combine all file contents into a single text string\n",
    "text = \"\\n\".join(all_texts)  # Join all texts with newline separators\n",
    "print(f\"Total files read: {len(all_texts)}\")  # Print total number of files read\n",
    "if all_texts:  # Check if any files were read\n",
    "    print(f\"Sample from first file: {all_texts[0][:100]}...\")  # Print first 100 characters of first file\n",
    "\n",
    "# Tokenize text into words\n",
    "def tokenize(text):  # Define function to tokenize text into words\n",
    "    # Simple word tokenization: split on whitespace and punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())  # Convert to lowercase and extract words using regex (regular expression)\n",
    "    return words  # Return list of words\n",
    "\n",
    "words = tokenize(text)  # Tokenize the combined text into a list of words\n",
    "vocab = sorted(list(set(words + ['<UNK>'])))  # Add <UNK> token for out-of-vocabulary words and create sorted vocabulary\n",
    "vocab_size = len(vocab)  # Calculate the size of the vocabulary (number of unique words + <UNK>)\n",
    "print(f\"Vocabulary size: {vocab_size}\")  # Print the vocabulary size\n",
    "print(f\"Sample words: {vocab[:10]}\")  # Print the first 10 words in the vocabulary for inspection\n",
    "\n",
    "# Create mapping from words to integers\n",
    "stoi = {w: i for i, w in enumerate(vocab)}  # Create dictionary mapping words to their indices\n",
    "itos = {i: w for i, w in enumerate(vocab)}  # Create dictionary mapping indices to their words\n",
    "def encode(s):  # Define function to encode a string into a list of word indices\n",
    "    # Encoder: input a string, output a list of integers, mapping OOV words to <UNK>\n",
    "    return [stoi.get(w, stoi['<UNK>']) for w in tokenize(s)]  # Map each word to its index, using <UNK> for OOV words\n",
    "\n",
    "decode = lambda l: ' '.join([itos[i] for i in l])  # Decoder: take a list of integers, output a string by joining words with spaces\n",
    "\n",
    "# Test encoding/decoding\n",
    "print(encode(\"hii there\"))  # Test encoding the string \"hii there\" into indices\n",
    "print(decode(encode(\"hii there\")))  # Test decoding the encoded indices back to a string\n",
    "\n",
    "# Splitting the data into training and validation\n",
    "data = torch.tensor(encode(' '.join(words)), dtype=torch.long)  # Encode the entire text into a tensor of word indices\n",
    "\n",
    "n = int(0.9*len(data))  # Calculate index to split data (90% for training, 10% for validation)\n",
    "train_data = data[:n]  # Split data into training set (first 90%)\n",
    "val_data = data[n:]  # Split data into validation set (last 10%)\n",
    "\n",
    "# Data loading\n",
    "def get_batch(split):  # Define function to generate a batch of input-target pairs\n",
    "    # Generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data  # Select training or validation data based on split\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))  # Randomly sample starting indices for batch\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])  # Create input tensor of shape (batch_size, block_size)\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])  # Create target tensor, shifted by one position\n",
    "    x, y = x.to(device), y.to(device)  # Move tensors to the specified device (CPU/GPU)\n",
    "    return x, y  # Return input and target tensors\n",
    "\n",
    "# Computing the loss\n",
    "@torch.no_grad()  # Disable gradient computation for efficiency\n",
    "def estimate_loss():  # Define function to estimate average loss on train and val sets\n",
    "    out = {}  # Initialize dictionary to store losses\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
    "    for split in ['train', 'val']:  # Iterate over train and validation splits\n",
    "        losses = torch.zeros(eval_iters)  # Initialize tensor to store losses for each iteration\n",
    "        for k in range(eval_iters):  # Perform eval_iters iterations\n",
    "            X, Y = get_batch(split)  # Get a batch of data for the current split\n",
    "            logits, loss = model(X, Y)  # Forward pass to compute logits and loss\n",
    "            losses[k] = loss.item()  # Store the loss value for this iteration\n",
    "        out[split] = losses.mean()  # Compute mean loss for the split\n",
    "    model.train()  # Set model back to training mode\n",
    "    return out  # Return dictionary of train and validation losses\n",
    "\n",
    "class Head(nn.Module):  # Define single attention head class\n",
    "    # One head of self-attention\n",
    "    def __init__(self, head_size):  # Initialize head with given head_size\n",
    "        super().__init__()  # Call parent class (nn.Module) initializer\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)  # Linear layer for key computation\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)  # Linear layer for query computation\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)  # Linear layer for value computation\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))  # Lower triangular mask for causal attention\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout layer for regularization\n",
    "\n",
    "    def forward(self, x):  # Define forward pass for the attention head\n",
    "        B, T, C = x.shape  # Extract batch size (B), sequence length (T), and embedding size (C)\n",
    "        # Self-attention performed by a single \"head\"\n",
    "        k = self.key(x)  # Compute keys: (B, T, head_size)\n",
    "        q = self.query(x)  # Compute queries: (B, T, head_size)\n",
    "        # Compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5  # Compute attention scores: (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))  # Mask future tokens for causal attention\n",
    "        wei = F.softmax(wei, dim=-1)  # Apply softmax to get attention weights\n",
    "        wei = self.dropout(wei)  # Apply dropout to attention weights\n",
    "        # Perform the weighted aggregation of the values\n",
    "        v = self.value(x)  # Compute values: (B, T, head_size)\n",
    "        out = wei @ v  # Aggregate values: (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n",
    "        return out  # Return attention output\n",
    "\n",
    "class MultiHeadAttention(nn.Module):  # Define multi-head attention class\n",
    "    # Multiple heads of self-attention in parallel\n",
    "    def __init__(self, num_heads, head_size):  # Initialize with number of heads and head size\n",
    "        super().__init__()  # Call parent class initializer\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])  # Create list of attention heads\n",
    "        self.projection = nn.Linear(n_embd, n_embd)  # Linear layer to project concatenated head outputs\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout layer for regularization\n",
    "        \n",
    "    def forward(self, x):  # Define forward pass for multi-head attention\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)  # Concatenate outputs from all heads along the last dimension\n",
    "        out = self.dropout(self.projection(out))  # Project concatenated output and apply dropout\n",
    "        return out  # Return multi-head attention output\n",
    "\n",
    "class FeedForward(nn.Module):  # Define feed-forward neural network class\n",
    "    # A simple linear layer followed by a non-linearity\n",
    "    def __init__(self, n_embd):  # Initialize with embedding size\n",
    "        super().__init__()  # Call parent class initializer\n",
    "        self.net = nn.Sequential(  # Define sequential network\n",
    "            nn.Linear(n_embd, 4*n_embd),  # First linear layer: expand to 4x embedding size\n",
    "            nn.ReLU(),  # ReLU activation for non-linearity\n",
    "            nn.Linear(4*n_embd, n_embd),  # Second linear layer: project back to embedding size\n",
    "            nn.Dropout(dropout),  # Dropout for regularization\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # Define forward pass for feed-forward network\n",
    "        return self.net(x)  # Pass input through the sequential network\n",
    "\n",
    "class Block(nn.Module):  # Define transformer block class\n",
    "    # Transformer block: communication followed by computation\n",
    "    def __init__(self, n_embd, n_head):  # Initialize with embedding size and number of heads\n",
    "        super().__init__()  # Call parent class initializer\n",
    "        head_size = n_embd // n_head  # Calculate size of each attention head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)  # Initialize multi-head attention\n",
    "        self.ffwd = FeedForward(n_embd)  # Initialize feed-forward network\n",
    "        self.ln1 = nn.LayerNorm(n_embd)  # Layer normalization for attention input\n",
    "        self.ln2 = nn.LayerNorm(n_embd)  # Layer normalization for feed-forward input\n",
    "\n",
    "    def forward(self, x):  # Define forward pass for transformer block\n",
    "        x = x + self.sa(self.ln1(x))  # Apply multi-head attention with residual connection\n",
    "        x = x + self.ffwd(self.ln2(x))  # Apply feed-forward network with residual connection\n",
    "        return x  # Return block output\n",
    "\n",
    "class WordLevelLanguageModel(nn.Module):  # Define word-level language model class\n",
    "    def __init__(self):  # Initialize the model\n",
    "        super().__init__()  # Call parent class initializer\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)  # Embedding layer for word indices\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)  # Embedding layer for position indices\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])  # Stack of transformer blocks\n",
    "        self.ln_f = nn.LayerNorm(n_embd)  # Final layer normalization\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)  # Linear layer to predict next word logits\n",
    "\n",
    "    def forward(self, idx, targets=None):  # Define forward pass for the model\n",
    "        B, T = idx.shape  # Extract batch size (B) and sequence length (T)\n",
    "        tok_emb = self.token_embedding_table(idx)  # Get token embeddings: (B, T, n_embd)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))  # Get position embeddings: (T, n_embd)\n",
    "        x = tok_emb + pos_emb  # Combine token and position embeddings: (B, T, n_embd)\n",
    "        x = self.blocks(x)  # Pass through transformer blocks: (B, T, n_embd)\n",
    "        x = self.ln_f(x)  # Apply final layer normalization: (B, T, n_embd)\n",
    "        logits = self.lm_head(x)  # Compute logits for next word: (B, T, vocab_size)\n",
    "\n",
    "        if targets is None:  # If no targets provided (e.g., during generation)\n",
    "            loss = None  # No loss to compute\n",
    "        else:  # If targets provided (e.g., during training)\n",
    "            B, T, C = logits.shape  # Extract logits shape\n",
    "            logits = logits.view(B*T, C)  # Reshape logits for loss computation: (B*T, vocab_size)\n",
    "            targets = targets.view(B*T)  # Reshape targets: (B*T,)\n",
    "            loss = F.cross_entropy(logits, targets)  # Compute cross-entropy loss\n",
    "        return logits, loss  # Return logits and loss (if computed)\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):  # Define method to generate new tokens\n",
    "        for _ in range(max_new_tokens):  # Generate up to max_new_tokens\n",
    "            idx_cond = idx[:, -block_size:]  # Crop context to last block_size tokens\n",
    "            logits, loss = self(idx_cond)  # Get logits for next token\n",
    "            logits = logits[:, -1, :]  # Focus on logits for the last time step: (B, vocab_size)\n",
    "            probs = F.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # Sample next token index: (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # Append sampled token to sequence\n",
    "        return idx  # Return generated sequence\n",
    "\n",
    "model = WordLevelLanguageModel()  # Instantiate the language model\n",
    "m = model.to(device)  # Move model to the specified device (CPU/GPU)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  # Initialize AdamW optimizer with model parameters\n",
    "\n",
    "# Optimization\n",
    "for iter in range(max_iters):  # Loop over training iterations\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:  # Check if evaluation is needed\n",
    "        losses = estimate_loss()  # Compute average train and validation losses\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")  # Print losses\n",
    "    \n",
    "    xb, yb = get_batch('train')  # Get a batch of training data\n",
    "    logits, loss = model(xb, yb)  # Forward pass to compute logits and loss\n",
    "    optimizer.zero_grad(set_to_none=True)  # Clear previous gradients\n",
    "    loss.backward()  # Compute gradients via backpropagation\n",
    "    optimizer.step()  # Update model parameters using gradients\n",
    "\n",
    "\n",
    "lossU = math.log(vocab_size)\n",
    "print(f\"Uniform probability loss (lossU): {lossU:.4f}\")\n",
    "      \n",
    "# Generate from the model\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)  # Initialize context with a single zero token\n",
    "print(decode(m.generate(context, max_new_tokens=5000)[0].tolist()))  # Generate and decode 100 new tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee6122-ad62-44e2-b1b2-64f9f3309106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
